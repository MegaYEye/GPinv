import tensorflow as tf
import numpy as np
from .likelihoods import TransformedLikelihood
from GPflow.tf_wraps import eye
from . import link_functions

class MultilatentLikelihood(TransformedLikelihood):
    """
    Base likelihood class for the multiple latent function model.
    In this model, the multiple latent functions are passed as large tensor to
    this class.
    Therefore, this class will divide the large tensor into multiple tensors
    according to self.slice_begin and self.slice_end
    These indices are generated by the method self.make_slice_indices(),
    which will be called by MultilatentLikelihood
    """
    def __init__(self, num_samples=20, jitter=1.0e-6, link_func = link_functions.Identity()):
        TransformedLikelihood.__init__(self, num_samples, jitter, link_func)

    def make_slice_indices(self, slice_begin, slice_size):
        """
        - input_list is a list of ModelInput object.
        In this method, list of slice_index is generated.
        """
        self.slice_begin = slice_begin
        self.slice_size  = slice_size

    def transform_tensor(self, F):
        """
        :param tf.tensor F: shape []
        """
        F_list = []
        for begin, size in zip(self.slice_begin, self.slice_size):
            F_list.append(tf.slice(F, [0,begin,0], [-1,size,-1]))
        return self.transform(F_list)

    def transform(self, F_list):
        """
        Transform of the latent functions to latent values.
        :param list of tf.tensor F_lit:
                        Samples for latent functions. Each tensor is sized
                        [num_samples, N, M]
        :return tf.tensor: Samples for the latent values at Y, sized
                                                        [num_samples', N', M']
        The return value should be real and vary around some values.
        E.G. the latent values that is limited to positive space should be
        projected into the entire real space by Log transform.
        """
        raise NotImplementedError


class MultilatentIndependent(MultilatentLikelihood):
    """
    This likelihood assumes that the data depend only on each channel of
    multiple latent functions.
    Therefore, the Cholesky factorization can be sped up.
    """
    def make_slice_indices(self, slice_begin, slice_size):
        """
        Make sure the all the slice sizes are the same.
        """
        for size in slice_size:
            assert size == slice_size[0]
        MultilatentLikelihood.make_slice_indices(self, slice_begin, slice_size)

    def getBlockDiagCov(self, cov):
        """
        :param tf.tensor cov: size [M, Nxn, Nxn], where M beging number of
        covariance (usually 1), N number of data point corresponding to
        Y.shape[0], n number of latent functions.
        :return tf.tensor: diag part of cov, sized [M, N, n, n]
        """
        M = tf.shape(cov)[0]
        N = self.slice_size[0]
        n = len(self.slice_size)
        cov = tf.reshape(cov, [M, 1, n*N, n, N])
        cov = tf.transpose(cov, [0,3,4,1,2])
        cov = tf.reshape(cov, [M, n, N, n, N])
        # shape [M, n, n, N]
        diag_cov = tf.batch_matrix_diag_part(tf.transpose(cov, [0,3,1,4,2]))
        # shape [M, N, n, n]
        return tf.transpose(diag_cov, [0, 3, 1, 2])

    def getCholeskyOf(self, cov):
        """
        :param tf.tensor cov: size [M, Nxn, Nxn], where M beging number of
        covariance (usually 1), N number of data point corresponding to
        Y.shape[0], n number of latent functions.
        Under the independent assuption, the covariance can be divided into
        N-matrices with size [M, n, n].
        """
        M = tf.shape(cov)[0]
        N = self.slice_size[0]
        n = len(self.slice_size)
        I = tf.tile(tf.expand_dims(tf.expand_dims(eye(n),[0]),[0]), [M,N,1,1])
        diag_chol = tf.batch_cholesky(self.getBlockDiagCov(cov)+self.jitter*I)
        # size [M, n, n, N, N]
        chol = tf.batch_matrix_diag(tf.transpose(diag_chol, [0,2,3,1]))
        # size [M, n, N, nxN]
        chol = tf.reshape(tf.transpose(chol, [0,1,3,2,4]), [M,n,N,n*N])
        # size [M, nxN, nxN]
        return tf.reshape(tf.transpose(chol, [0,3,1,2]), [M,n*N,n*N])
